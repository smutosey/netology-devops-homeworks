# Домашнее задание к занятию "" - `Александр Недорезов`

### Задача 1
Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD-операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести эту операцию:

- напишите список операций, которые вы будете производить для остановки запроса пользователя;
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB.


> #### Ответ:
> Найдём медленные операции: 
> ```js
> db.currentOp(
>    {
>      "active" : true,
>      "secs_running" : { "$gt" : 180 },
>    }
> )
> ```
> 
> И прервём выполнение операции по opid:
> ```js
> db.killOp(<opid>)
> ```
> 
> Варианты решения: 
> - оптимизировать запрос, построить план выполнения через cursor.explain() и db.collection.explain(), найти проблемные моменты, при необходимости построить индексы, либо другие методы из [MongoDB Query Optimization docs](https://www.mongodb.com/docs/manual/core/query-optimization/)
> - можно настроить таймер на максимально возможное время выполнения запросов - cursor.maxTimeMS(<time limit>)


---

### Задача 2
Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причём отношение количества записанных key-value-значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:

- сначала происходит рост отношения записанных значений к истекшим,
- Redis блокирует операции записи.

Как вы думаете, в чём может быть проблема?


> #### Ответ:
> Судя по всему, это проблема `Latency generated by expires`.  
> Каждые 100мс работает активный метод очистки просроченных записей. 
> За раз по умолчанию (ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP) можно пометить и очистить 20 устаревших записей, т.е. в секунду около 200.
> Но алгоритм адаптивный, и если обнаружится >25% устаревших записей, то он зациклится, и может заблокировать поток на запись в Redis, пока ключей не окажется <25%.
> Это необходимо, чтобы не использовать слишком много памяти для истекших ключей (ведь все хранится в оперативной памяти)  
> 
> `if the database has many, many keys expiring in the same second, and these make up at least 25% of the current population of keys with an expire set, Redis can block in order to get the percentage of keys already expired below 25%.`
> 
> Т.е. нужно иметь в виду, что если у нас много ключей, срок действия которых массово истекает по TTL в один момент, то это может стать источником повышения Latency или блокировок.


---

### Задача 3
Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей в таблицах базы
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```
Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения этой проблемы вы можете предложить?

> #### Ответ:
> Скорее всего проблема в timeout соединения из-за роста кол-ва записей, которые передаются по запросу. 
> 
> Для локализации необходимо сначала определить, на стороне клиента или сервера происходит разрыв. Посмотреть логи БД и клиента, метрики, в идеале трейсы запросов.
> Если проблема с сетью, то нужно увеличить net_read_timeout, по официальной документации с 30 до 60 оптимально
> (если причина, конечно, не кроется именно в сетевом оборудовании и инфраструктуре).
> 
> В качестве решения можно предложить:
> 1. Подумать, а нормально ли вообще, что пользователям необходимо постоянно запрашивать в клиенте условные миллионы строк? 
> Что они потом с ними делают? Может, на стороне СУБД реализовать какой-либо отчет, способный заменить им "ручные манипуляции" с выгрузкой?
> 2. Увеличить net_read_timeout, если сеть не справляется и исправить это нельзя
> 3. Увеличить значение параметров : connect_timeout, interactive_timeout, wait_timeout, либо max_allowed_packet 
> 4. Добавить ресурсов на сервер БД (а может и для клиента)
> 5. Проверить и исключить проблемы с I/O дисковых массивов
> 6. Оптимизировать запрос, создать индексы для оптимизации и ускорения (определить по explain запросов)
> 7. Как дополнительный вариант, можно расширить максимальное число соединений (max_connections), если можно распараллеливать запросы.



---

### Задача 4
Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объёмом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили эту проблему?

> #### Ответ:
> OOM - out of memory (нехватка памяти). OOM-killer - встроенный в систему механизм защиты от переполнения памяти. 
> Скорее всего PostgreSQL "съел" всю доступную память, и, чтобы предотвратить kernel panic (т.к. другим более важным процессам ОС не может выдать ресурсов), данный механизм завершил работу 
> или перезапустил сервис. 
> 
> Возможные решения:
> 1. Ограничить максимально доступную для субд память, "тонкий тюнинг" сервера PostgreSQL через параметры для работы с памятью: shared_buffer, work_mem, maintenance_work_mem.
> 2. Опять же оптимизация запросов и индексация таблиц.
> 3. Создать кластер, распределить нагрузку.
> 4. Увеличить доступные серверу ресурсы.


---